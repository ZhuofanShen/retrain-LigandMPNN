#!/bin/bash
#SBATCH --clusters=amarel
#SBATCH --partition=gpu
#SBATCH --job-name=LigandMPNN_training
#SBATCH --gres=gpu:1
#SBATCH --cpus-per-task 12
#SBATCH --mem=128g
#SBATCH --time=3-00:00:00
#SBATCH --output=slurm.%N.%j.log
#SBATCH --error=slurm.%N.%j.err
#SBATCH --requeue
#SBATCH --export=ALL
#SBATCH --begin=now
#SBATCH --open-mode=append

ulimit -n 65535
python ./train.py \
       --model_type "ligand_mpnn" \
       --num_neighbors 32 \
       --atom_context_num 25 \
       --cpus_per_task 12 \
       --num_epochs 200 \
       --num_examples_per_epoch 1000000 \
       --save_model_every_n_epochs 5 \
       --path_for_outputs "./model_checkpoints" \
       --path_for_training_data "./data" 
